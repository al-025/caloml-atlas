{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [2D Convolutions](#2D-Convolutions)\n",
    "- [3D Convolutions](#3D-Convolutions)\n",
    "- [Performance vs Dataset Size](#Performance-vs-Dataset-Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and some constants\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, LogNorm\n",
    "import pandas as pd\n",
    "import uproot as ur\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()\n",
    "\n",
    "path_prefix = '/AL/Phd/maxml/caloml-atlas/'\n",
    "plotpath = path_prefix+'classifier/Plots_var/'\n",
    "modelpath = path_prefix+'classifier/Models/'\n",
    "\n",
    "# import our resolution utilities\n",
    "import sys\n",
    "sys.path.append(path_prefix)\n",
    "from  util import resolution_util as ru\n",
    "from  util import plot_util as pu\n",
    "from  util import ml_util as mu\n",
    "\n",
    "inputpath = path_prefix+'inputs/'\n",
    "rootfiles = [\"pi0\", \"piplus\", \"piminus\"]\n",
    "\n",
    "trees, pdata = mu.setupPionData(inputpath, rootfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np0 = len(pdata['pi0'])\n",
    "npp = len(pdata['piplus'])\n",
    "npm = len(pdata['piminus'])\n",
    "\n",
    "print(\"Number of pi0 events: {}\".format(np0))\n",
    "print(\"Number of pi+ events: {}\".format(npp))\n",
    "print(\"Number of pi- events: {}\".format(npm))\n",
    "print(\"Total: {}\".format(np0+npp+npm))\n",
    "\n",
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer, flatten = False)\n",
    "        for layer in mu.cell_meta\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Convolution3D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import MaxPool3D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "gpu_list = [\"/gpu:0\"]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_classes = ['pi0','piplus']\n",
    "# create train/validation/test subsets containing 70%/10%/20%\n",
    "# of events from each type of pion event\n",
    "pdata_merged, pcells_merged, plabels = mu.createTrainingDatasets(training_classes, pdata, pcells)\n",
    "\n",
    "pcells_merged_reshaped = mu.reshapeSeparateCNN(pcells_merged)\n",
    "pcells_EMB2_channels = mu.setupChannelImages(mu.rescaleImages(pcells_merged, (16, 16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions\n",
    "<div style=\"text-align: right\"> <a href=\"#CNN-Variations\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_2d(model,filename='',\n",
    "               epochs=100):\n",
    "    '''\n",
    "    Convenience function for training and calculating\n",
    "    the area-under-curve for a model.\n",
    "    '''\n",
    "    \n",
    "    # check if model has been trained already\n",
    "    if Path(modelpath+filename+'.h5').is_file():\n",
    "        # load model\n",
    "        model = tf.keras.models.load_model(modelpath+filename+\".h5\")\n",
    "    else:\n",
    "        # train model\n",
    "        f_history = model.fit(pcells_EMB2_channels[pdata_merged.train],\n",
    "                            plabels[pdata_merged.train], \n",
    "                            validation_data=(pcells_EMB2_channels[pdata_merged.val],\n",
    "                                             plabels[pdata_merged.val]),\n",
    "                            epochs=epochs, batch_size=200*ngpu, verbose=2)\n",
    "        f_history = f_history.history\n",
    "\n",
    "        # save trained weights and history\n",
    "        if(filename != ''):\n",
    "            model.save(modelpath+filename+\".h5\")\n",
    "            with open(modelpath+filename +\".history\",'wb') as model_history_file:\n",
    "                pickle.dump(f_history, model_history_file)\n",
    "            \n",
    "    # get network scores for the dataset\n",
    "    f_score = model.predict(\n",
    "        pcells_EMB2_channels\n",
    "    )\n",
    "    \n",
    "    # calculate roc and auc\n",
    "    f_roc_fpr, f_roc_tpr, f_roc_thresh = roc_curve(\n",
    "        plabels[pdata_merged.test][:,1],\n",
    "        f_score[pdata_merged.test,1],\n",
    "        drop_intermediate=False,\n",
    "    )\n",
    "    f_roc_auc = auc(f_roc_fpr, f_roc_tpr)\n",
    "    \n",
    "    pu.roc_plot([f_roc_fpr], [f_roc_tpr],\n",
    "            figfile=plotpath+filename+'_roc.pdf',\n",
    "            labels=['area = {:.3f}'.format(f_roc_auc)],\n",
    "            extra_lines=[[[0, 1], [0, 1]]],\n",
    "            title=filename.replace('_','-')+' ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')\n",
    "    return f_roc_fpr, f_roc_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_nxn(n):\n",
    "    with strategy.scope():\n",
    "        # Here come the 16x16 inputs\n",
    "        input1 = Input(shape=(6, 16, 16), name='input1')\n",
    "        x = Convolution2D(32, (n, n), activation='relu', data_format = 'channels_first')(input1)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        output = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs = [input1], outputs = [output])\n",
    "        \n",
    "        # compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test models\n",
    "base_filename = 'conv2d_'\n",
    "\n",
    "res_fpr = []\n",
    "res_tpr = []\n",
    "res_auc = []\n",
    "for i in range(1,4+1):\n",
    "    fpr, tpr = test_model_2d(cnn_model_nxn(i),filename=base_filename+str(i)+'x'+str(i))\n",
    "    res_fpr.append(fpr)\n",
    "    res_tpr.append(tpr)\n",
    "    res_auc.append( auc(fpr, tpr) )\n",
    "    \n",
    "pu.roc_plot(res_fpr, res_tpr,\n",
    "            figfile=plotpath+'nxn_roc.pdf',\n",
    "            labels=['area({}) = {:.3f}'.format(str(i+1)+'x'+str(i+1),auc) for i,auc in enumerate(res_auc)],\n",
    "            extra_lines=[[[0, 1], [0, 1]]],\n",
    "            title='ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Convolutions\n",
    "<div style=\"text-align: right\"> <a href=\"#CNN-Variations\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_3d():\n",
    "    with strategy.scope():\n",
    "        input1 = Input(shape=(1, 6, 16, 16), name='input1')\n",
    "        x = Convolution3D(32, (2,2,2), activation='relu', data_format = 'channels_first')(input1)\n",
    "        x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        output = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs = [input1], outputs = [output])\n",
    "        \n",
    "        # compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model_3d()\n",
    "history = model.fit(np.expand_dims(pcells_EMB2_channels[pdata_merged.train],axis=1),\n",
    "                    plabels[pdata_merged.train], \n",
    "                    validation_data=(np.expand_dims(pcells_EMB2_channels[pdata_merged.val],axis=1),\n",
    "                    plabels[pdata_merged.val]),\n",
    "                    epochs=100, batch_size=200*ngpu, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(\n",
    "    np.expand_dims(pcells_EMB2_channels,axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_fpr, roc_tpr, roc_thresh = roc_curve(\n",
    "    plabels[pdata_merged.test][:,1],\n",
    "    scores[pdata_merged.test,1],\n",
    "    drop_intermediate=False,\n",
    ")\n",
    "roc_auc = auc(roc_fpr, roc_tpr)\n",
    "pu.roc_plot([roc_fpr], [roc_tpr],\n",
    "    figfile=plotpath+'conv3d_roc.pdf',\n",
    "    labels=['area(conv3d) = {:.3f}'.format(roc_auc)],\n",
    "    extra_lines=[[[0, 1], [0, 1]]],\n",
    "    title='ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_3d_depth(n):\n",
    "    with strategy.scope():\n",
    "        input1 = Input(shape=(1, 6, 16, 16), name='input1')\n",
    "        x = Convolution3D(32, (n,2,2), activation='relu', data_format = 'channels_first')(input1)\n",
    "        x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        output = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs = [input1], outputs = [output])\n",
    "        \n",
    "        # compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [3,4]\n",
    "model_depth = [cnn_model_3d_depth(n) for n in depths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d,m in zip(depths,model_depth):\n",
    "    history = m.fit(np.expand_dims(pcells_EMB2_channels[pdata_merged.train],axis=1),\n",
    "                    plabels[pdata_merged.train], \n",
    "                    validation_data=(np.expand_dims(pcells_EMB2_channels[pdata_merged.val],axis=1),\n",
    "                    plabels[pdata_merged.val]),\n",
    "                    epochs=100, batch_size=200*ngpu, verbose=2)\n",
    "    m.save(modelpath+\"conv3d_depth_\"+str(d)+\".h5\")\n",
    "    with open(modelpath+\"conv3d_depth_\"+str(d)+\".history\",'wb') as model_history_file:\n",
    "        pickle.dump(history.history, model_history_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_scores = []\n",
    "for m in model_depth:\n",
    "    depth_scores.append(m.predict(\n",
    "        np.expand_dims(pcells_EMB2_channels,axis=1)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_fpr = []\n",
    "depth_tpr = []\n",
    "depth_auc = []\n",
    "for s in depth_scores:\n",
    "    roc_fpr, roc_tpr, roc_thresh = roc_curve(\n",
    "        plabels[pdata_merged.test][:,1],\n",
    "        s[pdata_merged.test,1],\n",
    "        drop_intermediate=False,\n",
    "    )\n",
    "    depth_fpr.append(roc_fpr)\n",
    "    depth_tpr.append(roc_tpr)\n",
    "    depth_auc.append(auc(roc_fpr, roc_tpr))\n",
    "\n",
    "pu.roc_plot(depth_fpr, depth_tpr,\n",
    "    figfile=plotpath+'conv3d_depth_roc.pdf',\n",
    "    labels=['area({}x2x2) = {:.3f}'.format(str(d),auc) for d,auc in zip(depths,depth_auc)],\n",
    "    extra_lines=[[[0, 1], [0, 1]]],\n",
    "    title='ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs Dataset Size\n",
    "<div style=\"text-align: right\"> <a href=\"#CNN-Variations\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_2d_dataset_size(model,size,filename='',\n",
    "               epochs=100):\n",
    "    '''\n",
    "    Convenience function for training and calculating\n",
    "    the area-under-curve for a model using a fraction\n",
    "    of the full dataset.\n",
    "    '''\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    train_max = int(size*len(pcells_EMB2_channels[pdata_merged.train]))\n",
    "    train_index = rng.choice(len(pcells_EMB2_channels[pdata_merged.train]),size=train_max,replace=False)\n",
    "    \n",
    "    val_max = int(size*len(pcells_EMB2_channels[pdata_merged.val]))\n",
    "    val_index = rng.choice(len(pcells_EMB2_channels[pdata_merged.val]),size=val_max,replace=False)\n",
    "    \n",
    "    # check if model has been trained already\n",
    "    if Path(modelpath+filename+'.h5').is_file():\n",
    "        # load model\n",
    "        model = tf.keras.models.load_model(modelpath+filename+\".h5\")\n",
    "    else:\n",
    "        # train model\n",
    "        f_history = model.fit(pcells_EMB2_channels[pdata_merged.train][train_index],\n",
    "                            plabels[pdata_merged.train][train_index], \n",
    "                            validation_data=(pcells_EMB2_channels[pdata_merged.val][val_index],\n",
    "                                             plabels[pdata_merged.val][val_index]),\n",
    "                            epochs=epochs, batch_size=200*ngpu, verbose=2)\n",
    "        f_history = f_history.history\n",
    "\n",
    "        # save trained weights and history\n",
    "        if(filename != ''):\n",
    "            model.save(modelpath+filename+\".h5\")\n",
    "            with open(modelpath+filename +\".history\",'wb') as model_history_file:\n",
    "                pickle.dump(f_history, model_history_file)\n",
    "            \n",
    "    # get network scores for the dataset\n",
    "    f_score = model.predict(\n",
    "        pcells_EMB2_channels\n",
    "    )\n",
    "    \n",
    "    # calculate roc and auc\n",
    "    f_roc_fpr, f_roc_tpr, f_roc_thresh = roc_curve(\n",
    "        plabels[pdata_merged.test][:,1],\n",
    "        f_score[pdata_merged.test,1],\n",
    "        drop_intermediate=False,\n",
    "    )\n",
    "    f_roc_auc = auc(f_roc_fpr, f_roc_tpr)\n",
    "    \n",
    "    pu.roc_plot([f_roc_fpr], [f_roc_tpr],\n",
    "            figfile=plotpath+filename+'_roc.pdf',\n",
    "            labels=['area = {:.3f}'.format(f_roc_auc)],\n",
    "            extra_lines=[[[0, 1], [0, 1]]],\n",
    "            title=filename.replace('_','-')+' ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')\n",
    "    return f_roc_fpr, f_roc_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_baseline():\n",
    "    with strategy.scope():\n",
    "        input1 = Input(shape=(6, 16, 16), name='input1')\n",
    "        x = Convolution2D(32, (2,2), activation='relu', data_format = 'channels_first')(input1)\n",
    "        x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        output = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs = [input1], outputs = [output])\n",
    "        \n",
    "        # compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [0.2,0.4,0.6,0.8,1.0]\n",
    "size_fpr = []\n",
    "size_tpr = []\n",
    "size_auc = []\n",
    "for size in sizes:\n",
    "    fpr, tpr = test_model_2d_dataset_size(cnn_model_baseline(),size,\n",
    "                                         filename='dsetsize_'+str(size).replace('.',''))\n",
    "    size_fpr.append(fpr)\n",
    "    size_tpr.append(tpr)\n",
    "    size_auc.append(auc(fpr,tpr))\n",
    "    \n",
    "pu.roc_plot(size_fpr, size_tpr,\n",
    "    figfile=plotpath+'dsetsize_roc.pdf',\n",
    "    labels=['area({}) = {:.3f}'.format(str(s),auc) for s,auc in zip(sizes,size_auc)],\n",
    "    extra_lines=[[[0, 1], [0, 1]]],\n",
    "    title='ROC curve: classification of $\\pi^+$ vs. $\\pi^0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [20,40,60,80,100,150,200]\n",
    "epoch_fpr = []\n",
    "epoch_tpr = []\n",
    "epoch_auc = []\n",
    "for e in epochs:\n",
    "    fpr, tpr = test_model_2d_dataset_size(cnn_model_baseline(),1.0,\n",
    "                                         filename='epochsize_'+str(e),\n",
    "                                         epochs=e)\n",
    "    epoch_tpr.append(tpr)\n",
    "    epoch_fpr.append(fpr)\n",
    "    epoch_auc.append(auc(fpr,tpr))\n",
    "    \n",
    "pu.roc_plot(epoch_fpr, epoch_tpr,\n",
    "            figfile=plotpath+'epochsize_roc.pdf',\n",
    "            labels=['area({}) = {:.3f}'.format(str(e),auc) for e,auc in zip(epochs,epoch_auc)],\n",
    "            extra_lines=[[[0, 1], [0, 1]]],\n",
    "            title='ROC curves over epochs: classification of $\\pi^+$ vs. $\\pi^0$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
